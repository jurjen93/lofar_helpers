#!/bin/bash
#SBATCH --job-name=cortex_grid_search
#SBATCH -p gpu_h100
#SBATCH -t 08:00:00
#SBATCH --gpus 1
#SBATCH --output=out/multi_cortex%A_%a.out

set -e

cd ~/projects/lofar_helpers/neural_networks


module load 2023
source venv/bin/activate

# Read the parameter file
PARAM_FILE=parameters.txt

# Set default value for SLURM_ARRAY_TASK_ID
SLURM_ARRAY_TASK_ID=${SLURM_ARRAY_TASK_ID:=1}
# Extract the specific line corresponding to the SLURM_ARRAY_TASK_ID
PARAMS=$(sed -n "${SLURM_ARRAY_TASK_ID}p" $PARAM_FILE)

# Parse the parameters
read model lr normalize dropout_p batch_size <<< $PARAMS

# Execute your Python script with the given parameters
python train_nn.py $DATA_TRAINDATA_PATH --model $model --lr $lr --normalize $normalize --dropout_p $dropout_p --batch_size $batch_size
